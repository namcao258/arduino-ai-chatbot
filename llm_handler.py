"""
LLM Handler - X·ª≠ l√Ω giao ti·∫øp v·ªõi OpenAI API
"""
from openai import OpenAI
import json
from config import Config
from function_definitions import FUNCTIONS, SYSTEM_PROMPT
from context_memory import ContextMemory

class LLMHandler:
    def __init__(self):
        """Kh·ªüi t·∫°o OpenAI client"""
        Config.validate()  # Ki·ªÉm tra API key
        self.client = OpenAI(api_key=Config.OPENAI_API_KEY)
        self.model = Config.OPENAI_MODEL
        self.context_memory = ContextMemory()  # Th√™m context memory
        self.conversation_history = [
            {
                "role": "system",
                "content": SYSTEM_PROMPT
            }
        ]
        self.current_user_input = None  # L∆∞u input hi·ªán t·∫°i ƒë·ªÉ h·ªçc

    def add_user_message(self, message):
        """Th√™m tin nh·∫Øn ng∆∞·ªùi d√πng v√†o l·ªãch s·ª≠"""
        self.conversation_history.append({
            "role": "user",
            "content": message
        })
        self._trim_history()

    def add_assistant_message(self, message):
        """Th√™m tin nh·∫Øn AI v√†o l·ªãch s·ª≠"""
        self.conversation_history.append({
            "role": "assistant",
            "content": message
        })
        self._trim_history()

    def add_function_result(self, function_name, result):
        """Th√™m k·∫øt qu·∫£ function v√†o l·ªãch s·ª≠"""
        self.conversation_history.append({
            "role": "function",
            "name": function_name,
            "content": result
        })
        self._trim_history()

    def _trim_history(self):
        """Gi·ªõi h·∫°n ƒë·ªô d√†i l·ªãch s·ª≠ h·ªôi tho·∫°i (gi·ªØ system prompt)"""
        if len(self.conversation_history) > Config.MAX_CONVERSATION_HISTORY:
            # Gi·ªØ system prompt (ph·∫ßn t·ª≠ ƒë·∫ßu ti√™n)
            self.conversation_history = [self.conversation_history[0]] + \
                                       self.conversation_history[-(Config.MAX_CONVERSATION_HISTORY - 1):]

    def _inject_context_to_system_prompt(self):
        """Inject context memory v√†o system prompt"""
        context_summary = self.context_memory.get_context_summary()
        enhanced_prompt = SYSTEM_PROMPT + "\n\n" + context_summary

        # C·∫≠p nh·∫≠t system message
        self.conversation_history[0] = {
            "role": "system",
            "content": enhanced_prompt
        }

    def get_response(self, user_input):
        """
        G·ª≠i tin nh·∫Øn t·ªõi OpenAI v√† nh·∫≠n response

        Args:
            user_input: Tin nh·∫Øn t·ª´ ng∆∞·ªùi d√πng

        Returns:
            dict: {
                "needs_function_call": bool,
                "function_name": str ho·∫∑c None,
                "function_args": dict ho·∫∑c None,
                "message": str ho·∫∑c None
            }
        """
        self.current_user_input = user_input  # L∆∞u l·∫°i ƒë·ªÉ h·ªçc
        self.add_user_message(user_input)

        # Inject context v√†o prompt
        self._inject_context_to_system_prompt()

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=self.conversation_history,
                functions=FUNCTIONS,
                function_call="auto"
            )

            message = response.choices[0].message

            # Ki·ªÉm tra xem AI c√≥ mu·ªën g·ªçi function kh√¥ng
            if message.function_call:
                function_name = message.function_call.name
                function_args = json.loads(message.function_call.arguments)

                return {
                    "needs_function_call": True,
                    "function_name": function_name,
                    "function_args": function_args,
                    "message": None
                }
            else:
                # AI tr·∫£ l·ªùi b√¨nh th∆∞·ªùng
                ai_response = message.content
                self.add_assistant_message(ai_response)

                return {
                    "needs_function_call": False,
                    "function_name": None,
                    "function_args": None,
                    "message": ai_response
                }

        except Exception as e:
            return {
                "needs_function_call": False,
                "function_name": None,
                "function_args": None,
                "message": f"‚ùå L·ªói OpenAI API: {e}"
            }

    def get_final_response(self):
        """
        Sau khi th·ª±c thi function, g·ªçi l·∫°i OpenAI ƒë·ªÉ t·∫°o response cu·ªëi c√πng

        Returns:
            str: Response t·ª´ AI
        """
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=self.conversation_history
            )

            final_message = response.choices[0].message.content
            self.add_assistant_message(final_message)

            return final_message

        except Exception as e:
            return f"‚ùå L·ªói khi t·∫°o response: {e}"

    def record_action_to_memory(self, action, reason):
        """Ghi nh·∫≠n h√†nh ƒë·ªông v√†o memory ƒë·ªÉ h·ªçc"""
        if self.current_user_input:
            self.context_memory.record_action(action, reason, self.current_user_input)

            # H·ªçc s·ªü th√≠ch t·ª´ ho·∫°t ƒë·ªông
            activity = self.context_memory.extract_activity(self.current_user_input)
            if activity:
                self.context_memory.learn_preference(activity, action)

    def get_learned_stats(self):
        """L·∫•y th·ªëng k√™ nh·ªØng g√¨ ƒë√£ h·ªçc"""
        return self.context_memory.get_context_summary()

    def reset_conversation(self):
        """Reset l·ªãch s·ª≠ h·ªôi tho·∫°i (gi·ªØ l·∫°i system prompt)"""
        self.conversation_history = [
            {
                "role": "system",
                "content": SYSTEM_PROMPT
            }
        ]
        print("üîÑ ƒê√£ reset l·ªãch s·ª≠ h·ªôi tho·∫°i")
